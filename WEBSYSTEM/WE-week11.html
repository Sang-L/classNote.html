<! docytype html>



<html>
<head>
<h1>웹시스템 11주차 강의 노트</h1>
<h3><a href="../week-11.html">back</a></h3>
</head>

<body>

  Support Vector Machines<br><br><br>

-지지도 벡터 기계라 불림<br>
-1995년 Cortes와 Vapnik에 의해 제안<br>
-통계적 학습 이론에 기반<br>
-지지도 벡터라 불리는 훈련 사례의 부분 집합을 사용하여 의사 결정 경계를 표현<br>
-최대 마진 초평면 개념사용<br>
-고차원 데이터의 분류에 적합<br>
-선형 및 비선형 분리 데이터에도 적용<br><br>

1)적용 예<br>
-손으로 쓴 숫자 인식에서 텍스트 분류 등 많은 실제 응용에서 유망한 결과를 보여줌<br>
-마이크로 어레이 데이터(자료의 개수보다 차원이 큰 경우) 에 적용<br>
-고차원 데이터에도 잘 작동함 -> 차원문제에 robust함.<br><br>

2)<br>
-주어진 데이터를 분리하는 선형 초평면을 찾는 문제.<br>
-2차원 데이터의 경우, 선형 초평면은 직선이 됨.<br><br>

그림1<br><br>

3)초평면(Hyperplane)<br>
-서로 다른 두 클래스에 속하는 사례를 분리하는 기준 ex) 그림의 h1, h2<br>
-가능한 초평면의 개수는 무한<br>
-모든 가능한 초평면의 훈련 오차는 0이지만 알려지지 않은 사례에서도 동일하게 작동하는지 보장할 수 없음.<br>
-분류기는 시험 사례를 통해 성능에 따라 의사 결정 경계를 표현하는 여러 초평면들 중에서 하나를 선택<br>
-초평면 선택과 일반화 오차의 관계를 살펴서 선택<br>
-마진이 최대가 되는 초평면 선택<br>
그림2<br><br>

4)최대 마진 초평면<br>
)최대 마진<br>
-아이디어 : 큰 마진을 가진 의사 결정 경계는 작은 마진의 경우 보다 일반화 오류가 적음<br>
-마진이 작으면 의사결정경계의 작은 움직임도 분류에 상당한 영향을 미칠 수 있음<br>
)마진이 최대가 되도록 선형 분류기를 설계 -> 선형SVM<br><br>

5)벡터의 복습.<br>
내적과 외적 공식.<br>
그림3<br><br>

6)선형 의사 결정 경계<br>
-N개 훈련 사례로 구성된 이진 분류 문제<br>
-각 사례 : 그림4<br>
-선형 분류기의 의사 결정 경계<br>
:의사결정경계 : 그림4<br>
:선형 분류 함수 : 그림4<br>
:w바와 b는 모델의 매개변수, 훈련데이터를 통해 결정<br><br>

-의사 결정 경계 : 그림5<br>
-선혀 분류 함수 : 그림5<br>
-의서결정 경계(선형식) 위에 위치한 사례 : 그림5<br>
-의사결정경계 아래에 위치한 사례 : 그림5<br>
-경계 위 사례를 클래스1, 아래 사례를 클래스 -1이라 하면 : 그림5<br><br>

7)선형 분류기의 마진<br>
-2개의 사례(그림6)를 사용한 마진<br>
:의사 결정 경계에서 가장 가까운 사례<br>
:다른 분류에 속하는 사례 :  그림6<br><br>

-선형 분류함수 f(x)=w + x + b를 사용한 의사 결정 경계 (그림6)<br><br>

-의사결정경계의 마진, d는 위의 두 초평면의 거리에 의해 결정(그림6)<br>
(그림 7) <br><br>


8)선형 SVM 모델의 학습<br>
-SVM의 훈련 단계<br>
:훈련 데이터를 사용하여 인자 w바와 b를 추정<br>
:의사 결정 경계의 마진을 최대 -> ||w||를 최소<br>
:목표함수 : (그림8)<br>
:추가제약조건 (그림8)<br><br>


9)시험 사례의 분류<br>
-의사결정경계식 학습 후, W바와 b를 구한다.<br>
-시험사례 : 그림9<br><br>

10) 선형으로 분리 불가능할때?<br>
-비선형support vector machine<br>
-support vector regression방법<br>
(그림10)<br><br>

11)분리 불가능한 SVM<br>
-소프트 마진기법<br>
: 작은 훈련 오류를 허용할 수 있도록 변형하는 기법<br>
:클래스가 선형으로 분리되지 않는 상황에도 선형의 의사결정경계를 생성함<br>
:마진 폭과 선형 의사 결정 경계에 의해 발생하는 훈련 오류 수 사이의 타협점 고려<br>
:최적화 문제의 제한 조건에 양의 값을 가진 슬랙 변수를 추가<br><br>
 
--슬랙변수 (그림 11)<br><br>

12)SVR<br>
-SVM <br>
: 마진을 사용하여 겹치지 않는 두 클래스 간의 거리를 측정<br>
: 마진이 클수록 더 좋은 분류 결과<br><br>

-SVR<br>
: 서포트 벡터를 사용한 회귀 분석<br>
:자료들의 분리보다 자료들의 적합<br>
:회귀함수 둘레(tube)<br>
SVM의 마진에 해당<br>
가장 많은 데이터들을 포함하도록 설정<br>
:둘레에 포함되지 않는 데이터들은 슬랙 변수로 표현<br><br>

(그림12)<br><br>



13)SVM과 SVR의 비교<br>
(그림13)<br><br>



</body>
</html>
